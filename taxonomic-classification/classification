#!/bin/bash
# ============================================================================
# Taxonomic Classification Analysis Pipeline
# ============================================================================
#
# Usage:
#   classification [dorado|guppy|none]
#
# Requirements:
#   - Conda environment with all necessary tools installed
#   - Input data in the specified directories
#   - Sufficient computational resources (CPU, RAM, GPU for basecalling)
#
# Notes:
#   - Kraken2: minimum number of hit groups increased for higher accuracy
#     (i.e. fewer false positives).
#   - Increased confidence levels to reduce false positives
#
# Author: Cristina S. Mesquita
# Date: June 2024
# Version: 2.0
#
# ============================================================================

# Function to display help message
display_help() {
    cat << EOF
============================================================================
Taxonomic Classification Analysis Pipeline
============================================================================

Description:
  This script automates a long-reads taxonomic classification analysis workflow,
  including SUP basecalling, demultiplexing, quality control, k-mer analysis, and
  blast if intended. It supports several kraken2 databases.
  You may abort this script by pressing 'Ctrl+Shift+C'.

Usage:
  $0 [OPTIONS] <basecaller>

Arguments:
  basecaller    Basecaller to use. Must be either 'dorado', 'guppy' or 'none'

Options:
  -h, --help       Display this help message and exit
  -t, --threads    Number of threads to use (default: 16)
  -q, --qscore     Minimum quality score for reads (default: 7)

Examples:
  $0 dorado
  $0 -t 20 guppy
  $0 --qscore 10 dorado

============================================================================
EOF
}

# Detect the computer the script is being run to adjust the directories
current_user=$(whoami)
machine_name=$(hostname)
echo "$current_user @$machine_name"

if [[ "$machine_name" == "i3cris" ]]; then
    specific_user="cris"
elif [[ "$machine_name" == "i3SDiag-06u" ]]; then
    specific_user="i3sdiag"
else
    specific_user="$current_user"
fi

# Database paths
KRAKEN2DB="/media/U/#Bioinformatics/DBs/kraken2/littlePablos"
K2_PLUSPF="/media/U/#Bioinformatics/DBs/kraken2/PlusPF_16"
K2_FISH="/media/U/#Bioinformatics/DBs/kraken2/pathofish"
K2_REP="/media/U/#Bioinformatics/DBs/kraken2/rep040624"
#K2_NT="/media/U/#Bioinformatics/DBs/kraken2/nt"
BLAST_DB="/media/U/#Bioinformatics/DBs/Blast_core_nt/core_nt"
MEMORY_DB="/dev/shm"
#HUMAN_GENOME="/media/U/#Bioinformatics/DBs/GRCh38.p14.fna"
HUMAN_GENOME="/media/U/#Bioinformatics/DBs/kraken2/human.fna"


# Ensuring commands can be run
python3="/home/$specific_user/soft/miniconda3/envs/ont-diag/bin/python3"
extractreads="/home/$specific_user/soft/miniconda3/envs/ont-diag/bin/extract_kraken_reads.py"
combinekreports="/usr/bin/local/combine-sequential-kreports.py"
combinebracken="/usr/bin/local/combine-sequential-b-outputs.py"

# Verify if executables exist
if [[ ! -x "$combinekreports" || ! -x "$combinebracken" ]]; then
  echo "Error: One or more executable paths are incorrect or do not have execute permissions."
  exit 1
fi

# Function to display colored text
colored_text() {
    color=$1
    text=$2
    echo -e "\e[${color}m${text}\e[0m"
}

# Function to display yellow text
yellow_text() {
    colored_text 33 "$1"
}

# Logging setup with dynamic filename
SCRIPT_NAME=$(basename "$0" .sh)
TIMESTAMP=$(date +"%y%m%d-%H%M")  # Changed to YYMMDD_HHM format
LOG_DIR="/media/U/#Bioinformatics/.logfiles"
LOG_FILE="${LOG_DIR}/${SCRIPT_NAME}-${TIMESTAMP}.log"

# Logging function
log() {
    local level=$1
    local message=$2
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo "$timestamp [$level] $message" >> "$LOG_FILE"
}

# Function to log tool versions
log_tool_versions() {
    log "INFO" "Tool Versions:"
    log "INFO" "  rsync: $(rsync --version 2>&1 | head -n1)"
    log "INFO" "  python: $(python3 --version)"
    log "INFO" "  minimap: $(minimap2 --version 2>&1 | head -n1)"
    log "INFO" "  samtools: $(samtools --version 2>&1 | head -n1)"
    log "INFO" "  bbmask: $(bbmask.sh -h 2>&1 | head -n3 | tail -n1)"
    log "INFO" "  kraken2: $(kraken2 --version 2>&1 | head -n1)"
    log "INFO" "  krakentools: $(conda list | grep "krakentools" | awk '{print $2}')"
    log "INFO" "  bracken: $(bracken -v)"
    log "INFO" "  blastn: $(blastn -version 2>&1 | head -n1)"
    log ""
}

# Function to activate conda environment
activate_conda() {
  source /home/$specific_user/soft/miniconda3/etc/profile.d/conda.sh
  CONDA_ENV_NAME="ont-diag"
  log "DEBUG" "Activating conda environment: $CONDA_ENV_NAME"
  conda activate "$CONDA_ENV_NAME"
  if [[ $? -ne 0 ]]; then
    colored_text 31 "Error: Failed to activate conda environment ${CONDA_ENV_NAME}."
	log "ERROR" "Failed to activate conda environment ${CONDA_ENV_NAME}."
    exit 1
  fi
  # Ensure correct PATH
  #CONDA_PATH="/home/$specific_user/soft/miniconda3"
  #export PATH="${CONDA_PATH}/bin:$PATH"
  #conda env config vars set BLASTDB="/media/U/#Bioinformatics/DBs/Blast_core_nt"
  # make sure this has been run previously and the environment re-activated to take effect
}

# Parse command line arguments
parse_arguments() {
    BASECALLER=""
    THREADS=16
    QSCORE=7
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                display_help
                exit 0
                ;;
            -t|--threads)
                t="$2"
                shift 2
                ;;
            -q|--qscore)
                QSCORE="$2"
                shift 2
                ;;
            dorado|guppy|none)
                BASECALLER="$1"
                shift
                ;;
            *)
                echo "Unknown option: $1"
                display_help
                exit 1
                ;;
        esac
    done

    if [ -z "$BASECALLER" ]; then
        echo "Error: Basecaller (dorado, guppy or none) must be specified."
        display_help
        exit 1
    fi

  activate_conda
  log_tool_versions
  prompt_user
}

# Function to prompt the user for additional parameters
prompt_user() {
    if [[ "$BASECALLER" != "none" ]]; then
        # Basecalling is needed
        basecall --threads "$THREADS" --qscore "$QSCORE" "$BASECALLER"
        log "INFO" "Determining minimap2 preset based on technology: $TECHNOLOGY"
        if [[ "$TECHNOLOGY" = "R10" ]]; then
            m2preset="lr:hq"
            log "INFO" "Using m2preset: $m2preset for R10 technology"
        else
            m2preset="map-ont"
            log "INFO" "Using m2preset: $m2preset for non-R10 technology"
        fi
    else
        # No basecalling needed
        log "INFO" "No basecalling needed. Using existing basecalled reads."
        colored_text 34 "In order for the script to work, folder structure should be kept."
        log "WARN" "User reminded about maintaining folder structure"
        read -p "$(yellow_text 'Input full path to U: directory containing the settings file: ')" DIRECTORY
        log "INFO" "User input for settings directory: $DIRECTORY"
        log "INFO" "Reading settings file from ${DIRECTORY}/settings"
        while IFS= read -r line; do
            if [[ "$line" == *:* ]]; then # Ignore lines that don't contain ":"
                key=$(echo "$line" | cut -d ':' -f 1 | tr -d '[:space:]')
                value=$(echo "$line" | cut -d ':' -f 2- | sed 's/^[[:space:]]*//')
                declare "$key=$value" # Assign the value to a variable with the key as the variable name
                log "DEBUG" "Setting $key=$value"
            fi
        done < "${DIRECTORY}"/settings
        log "INFO" "Finished reading settings file"

        read -p "$(yellow_text 'Will you be running this locally (1) or remotely (2)? ')" RUNSIDE
        log "INFO" "User selected to run ${RUNSIDE}"
            if [[ "$RUNSIDE" = "1" ]]; then
                BASE_DIR="/home/$current_user/Documents/"${EXPERIMENT}/${SAMPLE}
                log "INFO" "Running locally. Base directory set to: $BASE_DIR"
                mkdir -p "${BASE_DIR}"
                log "DEBUG" "Created directory: $BASE_DIR"
                log "INFO" "Starting rsync of pod5 files"
                rsync --progress --update -ha "/media/U/RemoteAnalysis/"${EXPERIMENT}/${SAMPLE}/pod5 "${BASE_DIR}"
                log "INFO" "Finished rsync of pod5 files"
            else
                BASE_DIR="/media/U/RemoteAnalysis/"${EXPERIMENT}/${SAMPLE}
                log "INFO" "Running remotely. Base directory set to: $BASE_DIR"
            fi

        cd "$BASE_DIR" || { log "ERROR" "Failed to change directory to $BASE_DIR"; colored_text 31 "Error: Failed to change directory to $BASE_DIR"; exit 1; }
        echo "You currently are working in ${PWD} and your basecalled reads should be in ./basecall"
        log "INFO" "Current working directory: ${PWD}"

        echo "Importing previous settings: "
        echo "   ${EXPERIMENT} as experiment"
        echo "   ${SAMPLE} as sample"
        echo -e "   ${TECHNOLOGY} as technology used, for preset selection \n"

        log "INFO" "Importing previous settings"
        log "INFO" "EXPERIMENT: ${EXPERIMENT}, SAMPLE: ${SAMPLE}, TECHNOLOGY: ${TECHNOLOGY}"
        if [[ "$TECHNOLOGY" = "R10" ]]; then
            m2preset="lr:hq"
        else
            m2preset="map-ont"
        fi
        log "INFO" "m2preset set to: $m2preset based on technology: $TECHNOLOGY"
    fi
}

parse_arguments "$@"
# Start logging
if [ "$1" != "-h" ] && [ "$1" != "--help" ]; then
    log "DEBUG" "Script started with arguments: $*"
    log "INFO" "Using basecaller: $BASECALLER"
    log "INFO" "Threads: $THREADS"
    log "INFO" "Minimum Q-score: $QSCORE"
fi

########################################	DEFINITION OF CLASSIFICATION-ASSOCIATED FUNCTIONS		########################################

host_removal() {
	local HOSTS=$1
	cd "${BASE_DIR}"
	mkdir -p analysis/kraken2/hostremoval
	cd analysis/kraken2/hostremoval || exit 1
	log "INFO" "Starting host_removal function, with $m2preset as minimap2 preset"
	if [[ "$HOSTS" = "single" ]]; then
	    read -p "$(yellow_text 'Please input the full directory to the fasta/fna genome file of the host: ')" HOST
		log "INFO" "Host genome file: $HOST"
		for file in "${DATASETS}"/*.fastq; do
			sample=$(basename "$file" .fastq)
			log "INFO" "Processing sample: $sample"
			echo "   Mapping reads for $sample against the Host genome"
			minimap2 -t $t -ax $m2preset "${HOST}" "${file}" -o ${sample}_host.sam
			samtools fastq -@ 16 -n -f 4 ${sample}_host.sam > ${sample}_notHost.fastq
			samtools fastq -@ 16 -n -F 4 ${sample}_host.sam > ${sample}_Host.fastq
		done
		colored_text 32 "   Host-associated reads have now been removed"
		log "INFO" "Host removal completed successfully"
	else
		for file in "${DATASETS}"/*.fastq; do
			sample=$(basename "$file" .fastq)
			log "INFO" "Processing sample: $sample"
			echo "   Mapping reads for $sample against the Host genome"
			read -p "$(yellow_text 'Please input the full directory to the fasta/fna genome file of the host: ')" HOST
			log "INFO" "Host genome file: $HOST"
			minimap2 -t $t -ax $m2preset "${HOST}" "${file}" -o ${sample}_host.sam
			samtools fastq -@ 16 -n -f 4 ${sample}_host.sam > ${sample}_notHost.fastq
			samtools fastq -@ 16 -n -F 4 ${sample}_host.sam > ${sample}_Host.fastq
		done
		colored_text 32 "   Host-associated reads have now been removed"
		log "INFO" "Host removal completed successfully"
	fi
	cd "${BASE_DIR}" || exit 1
}

human_removal() {
	cd "${BASE_DIR}"
    mkdir -p analysis/kraken2/hostremoval
    cd analysis/kraken2/hostremoval || exit 1
	log "INFO" "Starting human_removal function, with $m2preset as minimap2 preset"
    read -p "$(yellow_text 'Would you like to remove potential vector contamination (UniVec_Core) as well? ')" UNIVEC
    if [[ "$UNIVEC" = "yes" ]]; then
        rsync -a --progress "${KRAKEN2DB}/Human_plus_UniVecCore"/*k2d "${MEMORY_DB}"
		log "INFO" "Copied Human_plus_UniVecCore database to memory"
        for file in "${DATASETS}"/*.fastq; do
			sample=$(basename "$file" .fastq)
			echo "   Mapping reads for $sample against the Human genome"
            if ls "${sample}"_notHost.fastq 1> /dev/null 2>&1; then
                INPUT_FILE="${sample}"_notHost.fastq
            else
                INPUT_FILE="${DATASETS}/${sample}".fastq
            fi
			log "INFO" "Input file: $INPUT_FILE"
			log "INFO" "Mapping $sample to human genome with minimap2"
            minimap2 -t $t -ax $m2preset "${HUMAN_GENOME}" "${INPUT_FILE}" -o "${sample}"_human.sam
            samtools fastq -@ 16 -n -f 4 "${sample}"_human.sam > "${sample}"_notHuman.fastq
            samtools fastq -@ 16 -n -F 4 "${sample}"_human.sam > "${sample}"_Human.fastq
            input_file="${BASE_DIR}/analysis/kraken2/hostremoval/${sample}"_notHuman.fastq
            log "INFO" "Running Kraken2 for $sample. Arguments: confidence=0.1, minimum-hit-groups=4"
			kraken2 --db "${MEMORY_DB}" --threads $t --confidence 0.1 --report "${sample}".k2report --memory-mapping --use-names --report-minimizer-data --minimum-hit-groups 4 \
                --unclassified-out "${sample}".k2unc --classified-out "${sample}".k2class "${input_file}" 2>> "${sample}".log > "${sample}".k2
        done
    else
        rsync -a --progress "${KRAKEN2DB}/onlyHuman"/*k2d "${MEMORY_DB}"
        log "INFO" "Copied onlyHuman database to memory"
		for file in "${DATASETS}"/*.fastq; do
			sample=$(basename "$file" .fastq)
			echo "   Mapping reads for $sample against the Human genome"
            if ls "${sample}_notHost.fastq" 1> /dev/null 2>&1; then
                INPUT_FILE="${sample}_notHost.fastq"
            else
                INPUT_FILE="${DATASETS}/${sample}.fastq"
            fi
			log "INFO" "Input file: $INPUT_FILE"
			log "INFO" "Mapping $sample to human genome with minimap2"
            minimap2 -t $t -ax $m2preset "${HUMAN_GENOME}" "${INPUT_FILE}" -o "${sample}"_human.sam
            samtools fastq -@ 16 -n -f 4 "${sample}_human.sam" > "${sample}"_notHuman.fastq
            samtools fastq -@ 16 -n -F 4 "${sample}_human.sam" > "${sample}"_Human.fastq
            log "INFO" "Running Kraken2 for $sample. Arguments: confidence=0.1, minimum-hit-groups=4"
            input_file="${BASE_DIR}"/analysis/kraken2/hostremoval/"${sample}"_notHuman.fastq
            kraken2 --db "${MEMORY_DB}" --threads $t --confidence 0.1 --report "${sample}".k2report --memory-mapping --use-names --report-minimizer-data --minimum-hit-groups 4 \
                --unclassified-out "${sample}".k2unc --classified-out "${sample}.k2class" "${input_file}" 2>> "${sample}".log > "${sample}".k2
        done
    fi
    colored_text 32 "   Human-associated reads have now been removed"
	log "INFO" "Removing temporary database files from memory"
	rm /dev/shm/*k2d
    log "INFO" "Human removal completed successfully"
}

# Helper function to handle Kraken2 runs
run_kraken2() {
    local DB_PATH=$1
    local DB_NAME=$2
    local CONFIDENCE=$3
    local THREADS=$4
	log "INFO" "Starting Kraken2 run for database: $DB_NAME"
    mkdir -p "$DB_NAME"
    cd "$DB_NAME" || { log "ERROR" "Cannot change to directory $DB_NAME"; colored_text 31 "Error: Cannot change to directory $DB_NAME"; exit 1; }
    date && echo "$DB_NAME: copying database to memory"
    log "INFO" "Copying database to memory: $DB_NAME"
	rsync --progress -a "${DB_PATH}"/*k2d "${MEMORY_DB}"
    date && echo "   DB successfully copied to memory"
	log "INFO" "Database successfully copied to memory: $DB_NAME"

    for file in "${BASE_DIR}"/basecall/*.fastq; do
		sample=$(basename "$file" .fastq)
        echo "   Running Kraken2 for $sample"
		log "INFO" "Running Kraken2 for sample: $sample"

        if ls ../*_masked.fastq 1> /dev/null 2>&1; then
            FASTQ_FILE="../${sample}_masked.fastq"
		elif ls ../*_fp.k2unc 1> /dev/null 2>&1; then
            FASTQ_FILE="${sample}_fp.k2unc"
        elif ls ../*.k2unc 1> /dev/null 2>&1; then
            FASTQ_FILE="../$sample.k2unc"
        else
            FASTQ_FILE="${BASE_DIR}"/analysis/kraken2/${sample}_masked.fastq
        fi
		colored_text 34 $FASTQ_FILE
        log "INFO" "Using FASTQ file: $FASTQ_FILE"
		log "INFO" "Starting Kraken2 classification for sample: $sample"
		log "INFO" "Arguments: confidence=$CONFIDENCE, threads=$THREADS, minimum-hit-groups=4"
		kraken2 --db "${MEMORY_DB}" --threads "$THREADS" --confidence "$CONFIDENCE" --memory-mapping --use-names \
            --report "${sample}.k2report" --report-minimizer-data --minimum-hit-groups 4 \
			--unclassified-out "${sample}.k2unc" --classified-out "${sample}.k2class" "${FASTQ_FILE}" \
            2>> "${sample}.log" > "${sample}.k2"
        log "INFO" "Finished Kraken2 classification for sample: $sample"
		date && echo "   Running Bracken for $sample"
		log "INFO" "Running Bracken for sample: $sample"
        bracken -r 200 -d "${DB_PATH}" -i "${sample}.k2report" -l S -o "${sample}.b" -w "${sample}.breport"
		log "INFO" "Finished Bracken for sample: $sample"

        if [ -s "${sample}.k2class" ]; then
            log "INFO" "Converting classified reads to FASTA for sample $sample: classified_"${sample}"_tovalidate.fasta"
			awk 'NR%4==1{printf ">%s\n", substr($0,2)} NR%4==2{print}' "${sample}.k2class" > classified_"${sample}"_tovalidate.fasta
        else
            colored_text 34 "Not converting to fasta as the classification file is empty (no reads classified)"
			log "WARN" "No reads classified for sample: $sample. Not converting to FASTA."
        fi
    done
    log "INFO" "Removing temporary database files from memory"
	rm /dev/shm/*k2d
    colored_text 32 "$DB_NAME: classification finished"
	log "INFO" "Classification finished for database: $DB_NAME"
}

# Kraken2: onlyUniVec_Core
kraken2_only_vec() {
    run_kraken2 "${KRAKEN2DB}/vectors/Core" "vector_removal" 0.05 "$t"
}

# Kraken2: archaea and bacteria
kraken2_arch_bac() {
    run_kraken2 "${KRAKEN2DB}/archaea_bacteria" "arch_bac" 0.05 "$t"
}

# Kraken2: viral
kraken2_vir() {
    run_kraken2 "${KRAKEN2DB}/viral" "vir" 0.01 "$t"
}

# Kraken2: eukaryota
kraken2_euk() {
    run_kraken2 "${KRAKEN2DB}/eukaryota" "euk" 0.05 "$t"
}


# Kraken2: PathoFish
kraken2_fish() {
    run_kraken2 "${K2_FISH}" "pathofish" 0.05 "$t"
}

# Kraken2: PlusPF
kraken2_pluspf() {
    run_kraken2 "${K2_PLUSPF}" "plusPF" 0.075 "$t"
	# exclude human and unclassified reads from file to validate classifications
    for file in ../plusPF/*.k2unc; do
		sample=$(basename "$file" .k2unc)
		rm classified_"${sample}"_tovalidate.fasta
        $python3 $extractreads -s "${sample}.k2class" -t 9606 0 --exclude \
            -o classified_notHuman_"${sample}"_tovalidate.fasta -k "${sample}.k2" -r "${sample}.k2report"
		log "INFO" "Extracting reads identified as human from classified file for sample $sample: classified_notHuman_"${sample}"_tovalidate.fasta"
    done
}

# Kraken2: Representative genomes from RefSeq
kraken2_rep() {
    local DB_PATH_1="${K2_REP}"/archaea_virus_fungi_protozoa
	local DB_PATH_2="${K2_REP}"/bacteria_p1
	local DB_PATH_3="${K2_REP}"/bacteria_p2
    local DB_NAME="repRefSeq"
    local CONFIDENCE=0.075
    local THREADS="$t"
	log "INFO" "Starting Kraken2 run for database: $DB_NAME"
	log "INFO" "Arguments: confidence=$CONFIDENCE, threads=$THREADS, minimum-hit-groups=4"
    mkdir -p "$DB_NAME"
    cd "$DB_NAME" || { log "ERROR" "Cannot change to directory $DB_NAME"; colored_text 31 "Error: Cannot change to directory $DB_NAME"; exit 1; }
    date && colored_text 34 "   This is a big database, it will be processed in three parts and then it will merge the outputs..."
	log "INFO" "Copying database to memory: $DB_NAME/archaea_virus_fungi_protozoa"
    rsync --progress -a "${DB_PATH_1}"/*k2d "${MEMORY_DB}"
	log "INFO" "Database successfully copied to memory"
    for file in "${BASE_DIR}"/basecall/*.fastq; do
		sample=$(basename "$file" .fastq)
        echo "   Running Kraken2 for $sample"
        if ls ../*_masked.fastq 1> /dev/null 2>&1; then
            FASTQ_FILE="../${sample}_masked.fastq"
        elif ls ../*.k2unc 1> /dev/null 2>&1; then
            FASTQ_FILE="../$sample.k2unc"
        else
            FASTQ_FILE="${BASE_DIR}"/analysis/kraken2/${sample}_masked.fastq
        fi
		colored_text 34 $FASTQ_FILE
		log "INFO" "Using FASTQ file: $FASTQ_FILE"
		log "INFO" "Starting Kraken2 classification for sample: $sample"
        kraken2 --db "${MEMORY_DB}" --threads "$THREADS" --confidence "$CONFIDENCE" --memory-mapping --use-names \
            --report "${sample}_avfp.k2report_temp" --report-minimizer-data --minimum-hit-groups 4 \
			--unclassified-out "${sample}_avfp.k2unc_temp" --classified-out "${sample}_avfp.k2class_temp" "${FASTQ_FILE}" \
            2>> "${sample}_avfp.log_temp" > "${sample}_avfp.k2_temp"
        log "INFO" "Finished repRefSeq/archaea_virus_fungi_protozoa Kraken2 classification for sample: $sample"
		date && echo "   Running Bracken for $sample"
        log "INFO" "Running Bracken for sample: $sample"
		bracken -r 200 -d "${DB_PATH_1}" -i "${sample}_avfp.k2report_temp" -l S -o "${sample}_avfp.b_temp" -w "${sample}_avfp.breport"
		log "INFO" "Finished repRefSeq/archaea_virus_fungi_protozoa Bracken for sample: $sample"
    done
    log "INFO" "Removing temporary database files from memory"
	rm /dev/shm/*k2d

	log "INFO" "Copying database to memory: $DB_NAME/bacteria_p1"
    rsync --progress -a "${DB_PATH_2}"/*k2d "${MEMORY_DB}"
	log "INFO" "Database successfully copied to memory"
    for file in "${BASE_DIR}"/basecall/*.fastq; do
		sample=$(basename "$file" .fastq)
		FASTQ_FILE="${sample}_avfp.k2unc_temp"
		log "INFO" "Using FASTQ file: $FASTQ_FILE"
		log "INFO" "Starting Kraken2 classification for sample: $sample"
        kraken2 --db "${MEMORY_DB}" --threads "$THREADS" --confidence "$CONFIDENCE" --memory-mapping --use-names \
            --report "${sample}_b1.k2report_temp" --report-minimizer-data --minimum-hit-groups 4 \
			--unclassified-out "${sample}_b1.k2unc_temp" --classified-out "${sample}_b1.k2class_temp" "${FASTQ_FILE}" \
            2>> "${sample}_b1.log_temp" > "${sample}_b1.k2_temp"
        log "INFO" "Finished repRefSeq/bacteria_p1 Kraken2 classification for sample: $sample"
        date && echo "   Running Bracken for $sample"
        log "INFO" "Running Bracken for sample: $sample"
        bracken -r 200 -d "${DB_PATH_2}" -i "${sample}_b1.k2report_temp" -l S -o "${sample}_b1.b_temp" -w "${sample}_b1.breport"
		log "INFO" "Finished repRefSeq/bacteria_p1 Bracken for sample: $sample"
    done
    log "INFO" "Removing temporary database files from memory"
	rm /dev/shm/*k2d

	log "INFO" "Copying database to memory: $DB_NAME/bacteria_p2"
    rsync --progress -a "${DB_PATH_3}"/*k2d "${MEMORY_DB}"
	log "INFO" "Database successfully copied to memory"
    for file in "${BASE_DIR}"/basecall/*.fastq; do
		sample=$(basename "$file" .fastq)
		FASTQ_FILE="${sample}_b1.k2unc_temp"
        log "INFO" "Using FASTQ file: $FASTQ_FILE"
		log "INFO" "Starting Kraken2 classification for sample: $sample"
		kraken2 --db "${MEMORY_DB}" --threads "$THREADS" --confidence "$CONFIDENCE" --memory-mapping --use-names \
            --report "${sample}_b2.k2report_temp" --report-minimizer-data --minimum-hit-groups 4 \
			--unclassified-out "${sample}_b2.k2unc_temp" --classified-out "${sample}_b2.k2class_temp" "${FASTQ_FILE}" \
            2>> "${sample}_b2.log_temp" > "${sample}_b2.k2_temp"
        log "INFO" "Finished repRefSeq/bacteria_p2 Kraken2 classification for sample: $sample"
		date && echo "   Running Bracken for $sample"
        log "INFO" "Running Bracken for sample: $sample"
		bracken -r 200 -d "${DB_PATH_3}" -i "${sample}_b2.k2report_temp" -l S -o "${sample}_b2.b_temp" -w "${sample}_b2.breport"
		log "INFO" "Finished repRefSeq/bacteria_p2 Bracken for sample: $sample"
    done
    log "INFO" "Removing temporary database files from memory"
    rm /dev/shm/*k2d

	# combine your temp output for each sample
    for file in "${BASE_DIR}"/basecall/*.fastq; do
		sample=$(basename "$file" .fastq)
		log "INFO" "Processing combined output for sample: $sample"
		# Find all .k2report_temp files in the directory
		k2_files=(./${sample}_*.k2report_temp)
		# Array to hold valid files with more than one line
		valid_k2=()
		# Check each file for more than one line
		for file in "${k2_files[@]}"; do
			if [ -f "$file" ] && [ "$(wc -l < "$file")" -gt 1 ]; then
				valid_k2+=("$file")
			fi
		done
		# Perform actions based on the number of valid files found
		if [ "${#valid_k2[@]}" -gt 1 ]; then
			log "INFO" "Combining multiple .k2report_temp files for $sample"
			$combinekreports --report-files "${valid_k2[@]}" --output ./"${sample}_combined.k2report" --only-combined
		elif [ "${#valid_k2[@]}" -eq 1 ]; then
			log "INFO" "Renaming single .k2report_temp file for $sample"
			mv "${valid_k2[0]}" "${sample}_combined.k2report"
		else
			log "WARN" "No valid .k2report_temp files found with more than one line for $sample"
			colored_text 34 "No valid .k2report_temp files found with more than one line for $sample."
		fi

		# Process .b_temp files
		b_files=(./${sample}_*.b_temp)
		valid_b=()
		for file in "${b_files[@]}"; do
			if [ -f "$file" ] && [ "$(wc -l < "$file")" -gt 1 ]; then
				valid_b+=("$file")
			fi
		done
		if [ "${#valid_b[@]}" -gt 1 ]; then
			log "INFO" "Combining multiple .b_temp files for $sample"
			$combinebracken --files "${valid_b[@]}" --output ./"${sample}_combined.b"
		elif [ "${#valid_b[@]}" -eq 1 ]; then
			log "INFO" "Renaming single .b_temp file for $sample"
			mv "${valid_b[0]}" "./${sample}_combined.b"
		else
			log "WARN" "No valid .b_temp files found with more than one line for $sample"
			colored_text 34 "No valid .b_temp files found with more than one line for $sample."
		fi

		# Combine and rename other temp files
		log "INFO" "Combining and renaming temporary files for $sample"
		cat "${sample}"_*.k2class_temp > "${sample}_combined.k2class"
		cat "${sample}"_*.log_temp > "${sample}_combined.log"
		cat "${sample}"_*.k2_temp > "${sample}_combined.k2"
		mv "${sample}_b2.k2unc_temp" "${sample}.k2unc"

		# exclude human and unclassified reads from file to validate classifications
        if [ -s "${sample}_combined.k2class" ]; then
			log "INFO" "Extracting non-human classified reads for $sample"
			$python3 $extractreads -s "${sample}_combined.k2class" -t 9606 0 --exclude \
				-o classified_notHuman_"${sample}"_tovalidate.fasta -k "${sample}_combined.k2" -r "${sample}_combined.k2report"
        else
            log "WARN" "Empty classification file for $sample, skipping extraction of non-human reads"
			colored_text 34 "Not converting to fasta as the classification file is empty (no reads classified)"
        fi
	done
	log "INFO" "Removing temporary files"
	rm *_temp

    colored_text 32 "$DB_NAME: classification finished"
	log "INFO" "Classification finished for database: $DB_NAME"
}


combine_reports_and_outputs() {
    local BASE_DIR="$1"
    local combinekreports="$2"
    local combinebracken="$3"

	log "INFO" "Starting combine_reports_and_outputs function"
    cd "${BASE_DIR}"/analysis/kraken2 || { 
        log "ERROR" "Failed to change directory to ${BASE_DIR}/analysis/kraken2"
        colored_text 31 "Failed to change directory to ${BASE_DIR}/analysis/kraken2"
        return 1
    }
    # Initialize associative arrays to store sample groups
    declare -A kreport_samples
    declare -A boutput_samples

    log "INFO" "Searching for .k2report and .b files"
    while IFS= read -r file; do
        # Check if the file has more than one line
        if [ "$(wc -l < "$file")" -le 1 ]; then
            log "WARN" "Skipping file with <= 1 line: $file"
			colored_text 34 "Skipping file with <= 1 line: $file"
            continue
        fi
        sample=$(basename "$file" | sed -E 's/(_combined)?(\.k2report|\.b)$//')
        log "DEBUG" "Processing file: $file, Sample name: $sample"
        # Append the file to the array under the sample key
        if [[ "$file" =~ \.k2report$ ]]; then
            kreport_samples["$sample"]+="$file "
        elif [[ "$file" =~ \.b$ ]]; then
            boutput_samples["$sample"]+="$file "
        fi
    done < <(find . -type f \( -name "*.k2report" -o -name "*.b" \))

	# Debugging: verify array contents
    log "DEBUG" "Contents of kreport_samples array:"
    for sample in "${!kreport_samples[@]}"; do
        log "DEBUG" "  Sample: $sample, Files: ${kreport_samples[$sample]}"
    done
    log "DEBUG" "Contents of boutput_samples array:"
    for sample in "${!boutput_samples[@]}"; do
        log "DEBUG" "  Sample: $sample, Files: ${boutput_samples[$sample]}"
    done

	# You can also use the declare -p command to print the entire array structure
    # log "DEBUG" "Full kreport_samples array structure:"
    # declare -p kreport_samples >> "${LOG_FILE}"
    # log "DEBUG" "Full boutput_samples array structure:"
    # declare -p boutput_samples >> "${LOG_FILE}"

    # Process .k2report files ; Iterate over the associative array for .k2report files and run the combine_sequential_kraken_reports.py script
    if [[ ${#kreport_samples[@]} -eq 0 ]]; then
        log "WARN" "No .k2report files found"
		colored_text 34 "No .k2report files found."
    else
        for sample in "${!kreport_samples[@]}"; do
            files="${kreport_samples[$sample]}"
            log "INFO" "Processing .k2report files for sample: $sample"
			echo "Processing .k2report files for sample: $sample"
            if [[ $(echo "$files" | wc -w) -eq 1 ]]; then
                log "INFO" "Only one .k2report file found for sample $sample. Copying file to destination."
				colored_text 34 "Only one .k2report file found for sample $sample. Copying file to destination."
                cp $files "${sample}_combined.k2report"
            else
                log "INFO" "Combining .k2report files for sample: $sample"
				echo "Combining .k2report files for sample: $sample"
                $combinekreports --report-files $files --output "${sample}_combined.k2report" --only-combined
            fi
        done
    fi

    # Process .b files ; Iterate over the associative array for .b files and run the combine_sequential_bracken_reports.py script
    if [[ ${#boutput_samples[@]} -eq 0 ]]; then
        log "WARN" "No .b files found"
		colored_text 34 "No .b files found."
    else
        for sample in "${!boutput_samples[@]}"; do
            files="${boutput_samples[$sample]}"
            log "INFO" "Processing .b files for sample: $sample"
			echo "Processing .b files for sample: $sample"
            if [[ $(echo "$files" | wc -w) -eq 1 ]]; then
                log "INFO" "Only one .b file found for sample $sample. Copying file to destination."
                colored_text 34 "Only one .b file found for sample $sample. Copying file to destination."
                cp $files "${sample}_combined.b"
            else
                log "INFO" "Combining .b files for sample: $sample"
				echo "Combining .b files for sample: $sample"
                # Extract directory names for each file to use as names
                names=$(for file in $files; do dirname "$file" | xargs basename; done | tr '\n' ',' | sed 's/,$//')
                log "DEBUG" "Names for .b files: $names"
				echo "Names: $names"
                $combinebracken --files $files --output "${sample}_combined.b" --names "$names"
            fi
        done
    fi
    log "INFO" "Combined kraken report and bracken output for each sample available at: analysis/kraken2"
	colored_text 32 "You may find a combined kraken report and bracken output for each sample @ analysis/kraken2."
}

# BlastN
blast_core_nt() {
	mkdir blast
    t=16
    cd blast || { log "ERROR" "Cannot change to directory blast"; colored_text 31 "Error: Cannot change to directory blast"; exit 1; }
	
	log "INFO" "Starting blast_core_nt function"
    for file in "${BASE_DIR}"/analysis/kraken2/*_masked.fastq; do
		sample=$(basename "$file" _masked.fastq)
        echo "   Creating files to run Blast for $sample"
        if ls ../*.k2unc 1> /dev/null 2>&1; then
            FASTQ_FILE="../$sample.k2unc"
			log "INFO" "Processing sample: $sample, using k2unc file: $FASTQ_FILE"
        else
            FASTQ_FILE="${BASE_DIR}"/analysis/kraken2/${sample}_masked.fastq
			log "INFO" "Processing sample: $sample, using masked fastq file: $FASTQ_FILE"
        fi
        TOBLAST_FASTA_FILE="../${sample}_toblast.fasta"
        if [ -s "${FASTQ_FILE}" ] && [ ! -f "${TOBLAST_FASTA_FILE}" ]; then
            echo "Converting ${FASTQ_FILE} to fasta"
            log "INFO" "Converting $FASTQ_FILE to fasta, considering minimum length of 250bp"
            reformat.sh in="${FASTQ_FILE}" out=${sample}_toblast.fasta minlength=250 ow=t uniquenames=t
        elif [ -f "${TOBLAST_FASTA_FILE}" ]; then
            colored_text 34 "${TOBLAST_FASTA_FILE} already exists, skipping conversion"
            log "INFO" "File already exists, skipping conversion of $TOBLAST_FASTA_FILE"
            ln -s "${TOBLAST_FASTA_FILE}" ${sample}_toblast.fastaln -s "${TOBLAST_FASTA_FILE}" ${sample}_toblast.fasta
        else
            colored_text 34 "Not converting to fasta as the file is empty"
            log "INFO" "Not converting to fasta as the file is empty"
        fi
	done
	for file in ./*.fasta; do
		sample=$(basename "$file" _toblast.fasta)
		echo "   Running Blast for $sample"
        log "INFO" "Running Blast for $sample versus the core_nt database"
		log "INFO" "Output file will these filtered hits: max_target_seqs=10, evalue=0.01, perc_identity=40, qcov_hsp_perc=35"
        cd "/media/U/#Bioinformatics/DBs/Blast_core_nt" # to make sure taxonomy works
		blastn -task dc-megablast -num_threads "$t" -db "${BLAST_DB}" -query ${original_dir}/blast/"${sample}_toblast.fasta" \
			-outfmt '6 qseqid sseqid sscinames scomnames qstart qend sstart send mismatch gaps gapopen length pident qcovs qcovhsp qcovus evalue bitscore' \
			-max_target_seqs 10 -evalue 0.01 -perc_identity 40 -qcov_hsp_perc 35 -out ${original_dir}/blast/"${sample}.blast"
	done
	colored_text 32 "Blast has finished. Output @ ${original_dir}/blast/${sample}.blast"
	colored_text 32 "Headers: readid, seqid, sciname, commonname, qstart, qend, sstart, send, mismatch, gaps, gapopen, length, pident, qcovs, qcovhsp, qcovus, evalue, bitscore"
    log "INFO" "Blast_core_nt function completed successfully"
}

# Main function to prompt user for database choice
main() {
    log "INFO" "Starting main function"
	while true; do
        echo "Available databases:"
        echo "1. only UniVec_Core"
        echo "2. archaea and bacteria"
        echo "3. viral"
		echo "4. eukaryota"
		echo "5. plusPF"
		echo "6. pathoFish"
		echo "7. RefSeq representative genomes (from 04/06/2024)"
		echo "8. Exit"
        read -p "$(yellow_text 'Enter the number of the database you want to search: ')" choice
		log "INFO" "User selected database choice: $choice"

        case $choice in
            1)
                log "INFO" "Running kraken2_only_vec"
				kraken2_only_vec
                ;;
            2)
                log "INFO" "Running kraken2_arch_bac"
				kraken2_arch_bac
                ;;
            3)
                "INFO" "Running kraken2_vir"
				kraken2_vir
                ;;
            4)
                log "INFO" "Running kraken2_euk"
				kraken2_euk
                ;;
            5)
                log "INFO" "Running kraken2_pluspf"
				kraken2_pluspf
                ;;
            6)
                log "INFO" "Running kraken2_fish"
				kraken2_fish
                ;;
			7)
				log "INFO" "Running kraken2_rep"
				kraken2_rep
                ;;
			8)
				log "INFO" "Exiting Kraken2 database search"
				colored_text 34 "No more Kraken2 databases to search. Exiting..."
				break
				;;
			*)
                log "WARN" "Invalid choice entered: $choice"
				colored_text 31 "Invalid choice. Please enter a number between 1 and 6."
                continue
                ;;
        esac
    done

# Store last directory to go there if required
original_dir=$(pwd)
log "INFO" "Original directory: $original_dir"

# Convert k2unc files to _toblast.fasta if not already converted
log "INFO" "Starting conversion of k2unc files to _toblast.fasta"
    for file in ./*.k2unc; do
        sample=$(basename "$file" .k2unc)
        TOBLAST_FASTA_FILE="${sample}_toblast.fasta"
        if [ -f "${file}" ] && [ ! -f "${TOBLAST_FASTA_FILE}" ]; then
            log "INFO" "Converting ${file} to fasta, with minimum length of 250bp"
			echo "Converting ${file} to fasta"
            reformat.sh in="${file}" out="${TOBLAST_FASTA_FILE}" minlength=250 ow=t uniquenames=t
        elif [ -f "${TOBLAST_FASTA_FILE}" ]; then
            log "INFO" "${TOBLAST_FASTA_FILE} already exists, skipping conversion"
			colored_text 34 "${TOBLAST_FASTA_FILE} already exists, skipping conversion"
        else
            log "WARN" "Not converting to fasta as there are no unclassified reads for ${sample}"
			colored_text 34 "Not converting to fasta as there are no unclassified reads."
        fi
    done

# Usage example
# combine_reports_and_outputs "/path/to/BASE_DIR" "/path/to/combine_sequential_kraken_reports.py" "/path/to/combine_sequential_bracken_reports.py"
combine_reports_and_outputs "${BASE_DIR}" "${combinekreports}" "${combinebracken}"

log "INFO" "Prompting user for BLAST run"
yellow_text "Would you like to run blast on still unclassified reads (might take a while to finish)"
read -p "$(yellow_text 'Beware that the core_nt database will be used (it is lighter and faster than standard_nt) (yes/no) ')" blastrun
log "INFO" "User response for BLAST run: $blastrun"
if [[ "${blastrun,,}" = "yes" ]]; then
    log "INFO" "Running BLAST on unclassified reads"
	cd ${original_dir}
    blast_core_nt
fi
}

########################################	MAIN CLASSIFICATION SCRIPT LOGIC	########################################
# General Parameters
DATASETS="${BASE_DIR}"/basecall
log "DEBUG" "DATASETS: ${DATASETS}"
log "DEBUG" "KRAKEN2DB: ${KRAKEN2DB}"
log "DEBUG" "PLUSPF: ${K2_PLUSPF}"
log "DEBUG" "K2_NT: ${K2_NT}"
log "DEBUG" "BLASTDB: ${BLAST_DB}"
log "DEBUG" "HUMAN: ${HUMAN_GENOME}"

conda activate "${CONDA_ENV_NAME}"
cd "${BASE_DIR}" || { log "ERROR" "Failed to change directory to ${BASE_DIR}"; exit 1; }
mkdir -p analysis/kraken2
cd analysis/kraken2 || { log "ERROR" "Failed to change directory to analysis/kraken2"; exit 1; }

log "INFO" "Displaying classification script information to user"
colored_text 34 "\nThe classification portion of this script is written to run functions based on your sequential preference."
colored_text 34 "To allow more flexibility you will be asked to select the Database to be searched and output will be saved in a sequential manner. \n"

# Host removal prompt
log "INFO" "Prompting user for host removal"
while true; do
    read -p "$(yellow_text 'Do you intend to remove host reads (non-human)? (yes/no) ')" HOST_REMOVAL
    HOST_REMOVAL=$(echo "$HOST_REMOVAL" | tr '[:upper:]' '[:lower:]') # convert to lowercase
    log "DEBUG" "User input for host removal: ${HOST_REMOVAL}"
	if [[ "$HOST_REMOVAL" = "yes" || "$HOST_REMOVAL" = "no" ]]; then
        break
    else
        log "WARN" "Invalid input for host removal"
		colored_text 31 "Invalid input. Please type 'yes' or 'no'."
    fi
done
if [[ "$HOST_REMOVAL" = "yes" ]]; then
    log "INFO" "User chose to remove host reads"
	while true; do
        read -p "$(yellow_text 'Are you removing the same host from all samples? Type 'no' if each sample has a different host (yes/no): ')" response
        response=$(echo "$response" | tr '[:upper:]' '[:lower:]') # convert to lowercase
        log "DEBUG" "User input for same host removal: ${response}"
		if [[ "$response" = "yes" ]]; then
			log "INFO" "Removing the same host from all samples"
			colored_text 34 "Removing the same host from all samples."
            host_removal "single"
            break
        elif [[ "$response" = "no" ]]; then
            log "INFO" "Removing different hosts for each sample"
			colored_text 34 "Different hosts for each sample."
            host_removal "multi"
            break
        else
            log "WARN" "Invalid input for host removal type"
			colored_text 31 "Invalid input. Please type 'yes' or 'no'."
        fi
    done
else
    log "INFO" "No host reads will be removed"
	colored_text 34 "No host reads will be removed."
	cd "${BASE_DIR}" || { log "ERROR" "Failed to change directory to ${BASE_DIR}"; exit 1; }
fi

# Human removal prompt
log "INFO" "Prompting user for human read removal"
while true; do
    read -p "$(yellow_text 'Do you wish to remove human reads? (yes/no) ')" HUMAN_REMOVAL
    HUMAN_REMOVAL=$(echo "$HUMAN_REMOVAL" | tr '[:upper:]' '[:lower:]') # convert to lowercase
    log "DEBUG" "User input for human removal: ${HUMAN_REMOVAL}"
	if [[ "$HUMAN_REMOVAL" = "yes" ]]; then
        log "INFO" "Removing human reads"
		human_removal
		break
    elif [[ "$HUMAN_REMOVAL" = "no" ]]; then
        log "INFO" "Not removing human reads"
        cd analysis/kraken2 || { log "ERROR" "Failed to change directory to analysis/kraken2"; exit 1; }
        echo "   Proceeding..."
		break
	else
        log "WARN" "Invalid input for human removal"
		colored_text 31 "Invalid input. Please type 'yes' or 'no'."
    fi
done

# Masking low complexity regions that may produce false positive hits
log "INFO" "Starting masking of low complexity regions"
echo "Masking reads before classification to reduce potential of false positive hits"
for file in "${DATASETS}"/*.fastq; do
    sample=$(basename "$file" .fastq)
    log "DEBUG" "Processing sample: ${sample}"
	# Check if $sample.k2unc exists in kraken2/hostremoval
    if [[ -f "${BASE_DIR}"/analysis/kraken2/hostremoval/${sample}.k2unc ]]; then
        bbinput="${BASE_DIR}"/analysis/kraken2/hostremoval/${sample}.k2unc
        bbout="${BASE_DIR}"/analysis/kraken2/hostremoval/${sample}_masked.fastq
    elif [[ -f "${BASE_DIR}"/analysis/kraken2/hostremoval/${sample}_notHost.fastq ]]; then
        bbinput="${BASE_DIR}"/analysis/kraken2/hostremoval/${sample}_notHost.fastq
        bbout="${BASE_DIR}"/analysis/kraken2/hostremoval/${sample}_masked.fastq
    else
        bbinput="${file}"
        bbout="${BASE_DIR}"/analysis/kraken2/${sample}_masked.fastq
    fi
    log "DEBUG" "Masking input: ${bbinput}, output: ${bbout}"
	log "INFO" "Masking parameters: uniquenames=t, entropy=0.01, minke=5, maxke=10, ow=t, minconsecutivebases=150"
	reformat.sh in="${bbinput}" out=stdout.fastq uniquenames=t | bbmask.sh in=stdin.fastq out=stdout.fastq entropy=0.01 minke=5 maxke=10 ow=t | reformat.sh in=stdin.fastq out="${bbout}" minconsecutivebases=150 int=f ow=t
    if [[ bbout="${BASE_DIR}"/analysis/kraken2/hostremoval/${sample}_masked.fastq ]]; then
        log "DEBUG" "Creating symlink for masked file: ${sample}_masked.fastq"
		ln -s "${BASE_DIR}"/analysis/kraken2/hostremoval/${sample}_masked.fastq "${BASE_DIR}"/analysis/kraken2/${sample}_masked.fastq
    fi
done
log "INFO" "Masking finished"
colored_text 32 "Masking finished"

# Call the main function to start the script
log "INFO" "Calling main function to start classification"
main

colored_text 32 "\nAll done!"
log "INFO" "Classification process completed"
